# Scalable Product Duplicate Detection

This project demonstrates a scalable approach to detecting duplicate products in large datasets. The implementation leverages techniques such as TF-IDF, Minhashing, and Locality Sensitive Hashing (LSH) to efficiently identify duplicate entries. The methodology also incorporates robust statistical evaluation through bootstrapping.

## Table of Contents
- [Introduction](#introduction)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Overview of Notebook Sections](#overview-of-notebook-sections)
  - [Data Cleaning](#data-cleaning)
  - [TF-IDF Selection of Features](#tf-idf-selection-of-features)
  - [Minhashing and LSH](#minhashing-and-lsh)
  - [MSM (Matching Similar Metrics)](#msm-matching-similar-metrics)
  - [Helper Functions](#helper-functions)
  - [Main (Bootstrapping and Evaluation)](#main-bootstrapping-and-evaluation)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)

---

## Introduction

Duplicate detection in product datasets is a critical task in e-commerce and inventory management. This project focuses on building a scalable pipeline for identifying such duplicates. The methodology combines feature extraction, efficient similarity measures, and statistical validation techniques.

---

## Getting Started

### Prerequisites
- Python 3.8 or higher
- Jupyter Notebook
- Virtual environment setup tools (optional but recommended)

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/<your-username>/Scalable-Product-Duplicate-Detection.git
   cd Scalable-Product-Duplicate-Detection
2. Install required dependencies:
   ```bash
   pip install -r requirements.text
3. Run the jupyter notebook:
   ```bash
   jupyter notebook implementation.ipynb


## Overview of Notebook Sections

### Data Cleaning
This section processes the raw dataset to prepare it for analysis. It involves handling missing values, normalising text fields, and other preprocessing tasks to ensure data consistency and reliability.

### TF-IDF Selection of Features
This section computes Term Frequency-Inverse Document Frequency (TF-IDF) scores for product descriptions. The highest-scoring terms are selected as features for downstream similarity computations.

### Minhashing and LSH
Here, Minhashing is applied to the TF-IDF vectors to generate compact representations of the data. Locality Sensitive Hashing (LSH) is then used to group similar items into candidate sets for duplicate detection.

### MSM (Matching Similar Metrics)
This section defines and computes similarity metrics used to evaluate whether two products are duplicates. These metrics are applied to candidate sets generated by the LSH step.

### Helper Functions
A collection of utility functions that support the implementation, such as functions for data manipulation, visualization, and metric calculations.

### Main (Bootstrapping and Evaluation)
The main execution section of the notebook. It performs bootstrapping to validate the robustness of the duplicate detection pipeline and evaluates the results using performance metrics such as precision, recall, and F1-score.

---

## Results
The duplicate detection system was evaluated on a large dataset, demonstrating its efficiency and scalability. The use of TF-IDF, Minhashing, and LSH significantly reduced computation time while maintaining high accuracy.


   


   



